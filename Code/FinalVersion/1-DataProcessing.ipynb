{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing: data collection, data pre-processing, data modelling, data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install requests\n",
    "# %pip install bs4\n",
    "# %pip install lxml\n",
    "\n",
    "# %pip install spacy\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !python -m spacy download en\n",
    "# %pip install gensim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages for supporting manipulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection\n",
    "import pandas as pd     # working with relational or labeled data easily and intuitively.\n",
    "import csv          # implements classes to read and write tabular data in CSV format.\n",
    "# warnings\n",
    "import warnings     # Warnings provided situations that aren’t necessarily exceptions.\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "import requests     # Requests allows you to send HTTP/1.1 requests extremely easily\n",
    "from bs4 import BeautifulSoup       #  scrape information from web pages. \n",
    "import lxml         # lxml is a Python library which allows for easy handling of XML and HTML files, and can also be used for web scraping.\n",
    "import urllib3      # urllib3 is a powerful, user-friendly HTTP client for Python\n",
    "\n",
    "# Data pre-processing\n",
    "import re           # regular expression matching operations\n",
    "import spacy\n",
    "from gensim.corpora.dictionary import Dictionary    # Dictionary encapsulates the mapping between normalized words and their integer ids.\n",
    "\n",
    "# Data modelling\n",
    "from gensim.models.tfidfmodel import TfidfModel     # This module implements functionality related to the Term Frequency - Inverse Document Frequency class of bag-of-words vector space models.\n",
    "from gensim.models.ldamulticore import LdaMulticore     # Online Latent Dirichlet Allocation (LDA) in Python, using all CPU cores to parallelize and speed up model training.\n",
    "from gensim.models.nmf import Nmf                       # a visual explainer and Python Implementation\n",
    "from gensim.models.lsimodel import LsiModel             # LSI is an NLP approach that is particularly useful in distributional semantics.\n",
    "\n",
    "# Data analysis\n",
    "import gensim\n",
    "from gensim import corpora, similarities\n",
    "from gensim.models import Word2Vec                      # Word2Vec consists of models for generating word embedding. Word Embedding is a language modeling technique used for mapping words to vectors of real numbers.\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex        # A term similarity index that computes cosine similarities between word embeddings.\n",
    "# SoftCosineSimilarity: to retrieve documents most similar to a query and compare the performance against other similarity measures.\n",
    "# SparseTermSimilarityMatrix: Compute similarity against a corpus of documents by storing the sparse index matrix in memory. The similarity measure used is cosine between two vectors.\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/1492083144.py:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  retrievalHistoryReport = pd.read_csv('history.csv', lineterminator='\\n', sep=',', header=0, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "# getting a two-dimensional dataframe with labeled axes from a comma-sperated values file and indexing each lines\n",
    "\n",
    "retrievalHistoryReport = pd.read_csv('history.csv', lineterminator='\\n', sep=',', header=0, error_bad_lines=False)\n",
    "retrievalHistoryReport.index = range(len(retrievalHistoryReport))\n",
    "\n",
    "# read csv file as a two-dimensional list \n",
    "csv_reader = csv.reader(open(\"./history.csv\"))\n",
    "links = []  # the axis of links in dataframe retrievalHistoryReport\n",
    "for line in csv_reader:\n",
    "    links.append(line)\n",
    "links = links[1:]\n",
    "\n",
    "# approximately scraping text in the links in <p> tags and putting captured text into dataframe retrievalHistoryReport\n",
    "def getContent(links) -> list:\n",
    "    content = []\n",
    "    for link in links:\n",
    "        r = requests.get(link[0], verify=False)  \n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "        oneline=''\n",
    "        for link in soup.find_all(\"p\"):\n",
    "            oneline+=link.get_text()\n",
    "        content.append(oneline)\n",
    "    return content\n",
    "\n",
    "content = getContent(links)\n",
    "retrievalHistoryReport['content'] = content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")          # applied English NLP model\n",
    "nlp.max_length=5563920\n",
    "\n",
    "# Normalization \n",
    "retrievalHistoryReport['content'] = retrievalHistoryReport['content'].astype('str') # transformed data type\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub('[!\"”$%&’()*+,-./:;<=>?[\\\\]^_`{|}~@#]','',text)   # Removing special characters \n",
    "    text = text.lower()                                             # convert all words to lower case\n",
    "    return text\n",
    "retrievalHistoryReport['content'] = retrievalHistoryReport.content.apply(preprocess)\n",
    "\n",
    "removal= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']    # remove stopwords, as these do not contribute a lot to the information in the sentences.\n",
    "tokens = []\n",
    "for doc in nlp.pipe(retrievalHistoryReport['content']):\n",
    "    proj_tok = [token.lemma_ for token in doc if token.pos_ not in removal and not token.is_stop]   # lemmanization and removing meaningless words\n",
    "    tokens.append(proj_tok)\n",
    "retrievalHistoryReport['tokens'] = tokens       # Normalized data\n",
    "\n",
    "for doc in range(len(retrievalHistoryReport)):  # 如果token里没有词，就drop掉不参与计算\n",
    "    if(len(retrievalHistoryReport['tokens'][doc]) < 1):\n",
    "        retrievalHistoryReport.drop([doc],inplace = True)\n",
    "\n",
    "# calculate frequencies of all tokens and sorted result descending\n",
    "word_count = dict()\n",
    "for text in retrievalHistoryReport['tokens']:\n",
    "  for word in text:\n",
    "    if word in word_count:  \n",
    "      word_count[word] += 1\n",
    "    else:\n",
    "      word_count[word] = 1\n",
    "sorted(word_count.items(), key = lambda x:x[1], reverse=True)\n",
    "\n",
    "# concert normalized tokens to dictionary and filter outliers out following the sorted result\n",
    "dictionary = Dictionary(retrievalHistoryReport['tokens'])\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.8, keep_n=250)\n",
    "\n",
    "# Gathering tokens in each doc together into one corpus.\n",
    "# Convert document into the bag-of-words (BoW) format = list of (token_id, token_count) tuples.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in retrievalHistoryReport['tokens']]  #Corpus shows tokens in each document and its frequency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    20\n",
       "8    13\n",
       "5     9\n",
       "1     9\n",
       "6     9\n",
       "4     4\n",
       "2     4\n",
       "7     3\n",
       "0     2\n",
       "Name: topic_lda, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setting n topics, and assign each token a topic through LDA model\n",
    "\"\"\"\n",
    "# Modelling in 3 algorithms\n",
    "lda_model = LdaMulticore(corpus, id2word=dictionary, iterations=26, num_topics=9, workers=4, passes=36)\n",
    "# lsi_model = LsiModel(corpus, id2word=dictionary, power_iters=1, num_topics=9, onepass=100)\n",
    "# nmf_model = Nmf(corpus, id2word=dictionary, w_max_iter=56, num_topics=9, passes=90)\n",
    "\n",
    "# Getting topic probability distribution\n",
    "transformed_doc_lda = lda_model[corpus]\n",
    "# transformed_doc_lsi = lsi_model[corpus]\n",
    "# transformed_doc_nmf = nmf_model[corpus]\n",
    "\n",
    "# Add topics column to dataframe which has the most probable topic that each article belong to.\n",
    "retrievalHistoryReport['topic_lda'] = [sorted(transformed_doc_lda[doc], key=lambda x:x[1], reverse=True)[0][0] for doc in range(len(retrievalHistoryReport['content']))]\n",
    "\n",
    "# count the document frequency of each topic\n",
    "retrievalHistoryReport.topic_lda.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/var/folders/fc/xgt611892s1d8k4y_6gmdv1c0000gn/T/ipykernel_33883/2508819764.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>database, type, create, provide, number, new, use, code, statement, error</td>\n",
       "      <td>[weâve, train, model, call, chatgpt, interact, conversational, way, dialogue, format, make, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>file, directory, method, python, page, module, check, cookie, stand, browserredirectingplease</td>\n",
       "      <td>[stand, check, browserredirectingplease, enable, cookie, reload, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>file, directory, method, python, page, module, check, cookie, stand, browserredirectingplease</td>\n",
       "      <td>[stand, check, browserredirectingplease, enable, cookie, reload, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>module, python, start, output, issue, cause, run, instal, program, interact</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>module, python, start, output, issue, cause, run, instal, program, interact</td>\n",
       "      <td>[jupyter, kernels, crash, number, reason, instal, incompatible, package, unsupported, os, versio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             5.0              0.8576   \n",
       "1            1             8.0              0.8889   \n",
       "2            2             8.0              0.8889   \n",
       "3            3             7.0              0.9731   \n",
       "4            4             7.0              0.9731   \n",
       "\n",
       "                                                                                        Keywords  \\\n",
       "0                      database, type, create, provide, number, new, use, code, statement, error   \n",
       "1  file, directory, method, python, page, module, check, cookie, stand, browserredirectingplease   \n",
       "2  file, directory, method, python, page, module, check, cookie, stand, browserredirectingplease   \n",
       "3                    module, python, start, output, issue, cause, run, instal, program, interact   \n",
       "4                    module, python, start, output, issue, cause, run, instal, program, interact   \n",
       "\n",
       "                                                                                              Document  \n",
       "0  [weâve, train, model, call, chatgpt, interact, conversational, way, dialogue, format, make, po...  \n",
       "1                               [stand, check, browserredirectingplease, enable, cookie, reload, page]  \n",
       "2                               [stand, check, browserredirectingplease, enable, cookie, reload, page]  \n",
       "3                                                                                                  NaN  \n",
       "4  [jupyter, kernels, crash, number, reason, instal, incompatible, package, unsupported, os, versio...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Getting the Dominant topic, Topic Percent Contribution for each document\n",
    "Calculating tokens in each doc group by topics, then making the token of the most greatest frequency as the dominante topic of each document.\n",
    "1. After self-labeling the docs during user exploration via dominant topic of each doc, \n",
    "    the clustered data could be accumulated over time then used as user recommendations.\n",
    "2. After clustering data, calculating docs group by its dominant topics.  \n",
    "    It can ensure the dominant topic which calculated among the all docs reliable as this avoids that \n",
    "    all the tokens of dominant topic of all docs shows greatest frequency appears in limited documents.\n",
    "    It means that it is possible that the dominant topic calculated before might not be the exact dominant topic user explored and this is a method to check. \n",
    "    If the dominant topics are also the dominant topics of most documents, the dominant topic is true. \n",
    "\"\"\"\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=retrievalHistoryReport['tokens']):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get dominant topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)     # topic_num: 主题， prop_topic: tokens占比\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=retrievalHistoryReport['tokens'])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Document']\n",
    "df_dominant_topic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>file, mode, version, directory, function, system, set, define, block, follow</td>\n",
       "      <td>[product, update, company, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>try, research, problem, project, open, issue, contact, find, log, cookie</td>\n",
       "      <td>[jupyter, kernels, crash, number, reason, instal, incompatible, package, unsupported, os, versio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>value, python, list, return, type, access, object, account, specify, order</td>\n",
       "      <td>[harness, productivity, design, collaboration, celebrate, builtin, security, welcome, platform, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>release, system, update, product, news, company, version, code, source, os</td>\n",
       "      <td>[python, method, getcwd, return, current, work, directory, processfollowing, syntax, getcwd, met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>object, return, parameter, version, value, set, default, attribute, method, file</td>\n",
       "      <td>[new, github, create, account]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>database, type, create, provide, number, new, use, code, statement, error</td>\n",
       "      <td>[weâve, train, model, call, chatgpt, interact, conversational, way, dialogue, format, make, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>python, user, upload, module, learn, google, os, file, project, cookie</td>\n",
       "      <td>[product, update, company, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>module, python, start, output, issue, cause, run, instal, program, interact</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>file, directory, method, python, page, module, check, cookie, stand, browserredirectingplease</td>\n",
       "      <td>[pip, install, browserhistory, copy, pip, instruction, release, feb, simple, module, extract, br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.9382   \n",
       "1        1.0              0.9671   \n",
       "2        2.0              0.9980   \n",
       "3        3.0              0.9957   \n",
       "4        4.0              0.9984   \n",
       "5        5.0              0.8576   \n",
       "6        6.0              0.9811   \n",
       "7        7.0              0.9731   \n",
       "8        8.0              0.9970   \n",
       "\n",
       "                                                                                        Keywords  \\\n",
       "0                   file, mode, version, directory, function, system, set, define, block, follow   \n",
       "1                       try, research, problem, project, open, issue, contact, find, log, cookie   \n",
       "2                     value, python, list, return, type, access, object, account, specify, order   \n",
       "3                     release, system, update, product, news, company, version, code, source, os   \n",
       "4               object, return, parameter, version, value, set, default, attribute, method, file   \n",
       "5                      database, type, create, provide, number, new, use, code, statement, error   \n",
       "6                         python, user, upload, module, learn, google, os, file, project, cookie   \n",
       "7                    module, python, start, output, issue, cause, run, instal, program, interact   \n",
       "8  file, directory, method, python, page, module, check, cookie, stand, browserredirectingplease   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0                                                                     [product, update, company, news]  \n",
       "1  [jupyter, kernels, crash, number, reason, instal, incompatible, package, unsupported, os, versio...  \n",
       "2  [harness, productivity, design, collaboration, celebrate, builtin, security, welcome, platform, ...  \n",
       "3  [python, method, getcwd, return, current, work, directory, processfollowing, syntax, getcwd, met...  \n",
       "4                                                                       [new, github, create, account]  \n",
       "5  [weâve, train, model, call, chatgpt, interact, conversational, way, dialogue, format, make, po...  \n",
       "6                                                                     [product, update, company, news]  \n",
       "7                                                                                                  NaN  \n",
       "8  [pip, install, browserhistory, copy, pip, instruction, release, feb, simple, module, extract, br...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Getting the Dominant topic, Topic Percent Contribution for all documents\n",
    "1. Calculating percent contribution of dominant topic of each doc group by dominant topics, then making the token of the top-10 frequencies as the dominante topics of all documents.\n",
    "2. The main goal and side goals of user exploration can be detected by analysing topic distribution result and other situations may have relation between topiccs.\n",
    "\"\"\"\n",
    "pd.options.display.max_colwidth = 100       # Display setting to show more characters in column\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')      \n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], axis=0)\n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)        # Reset Index: change the index from Doc No. to new order\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "sent_topics_sorteddf_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:00<00:00, 96672.48it/s]\n",
      "/Users/bug/opt/anaconda3/envs/TopicModellingEnvi/lib/python3.9/site-packages/gensim/similarities/termsim.py:382: RuntimeWarning: divide by zero encountered in divide\n",
      "  normalized_corpus = np.multiply(corpus, 1.0 / corpus_norm)\n",
      "/Users/bug/opt/anaconda3/envs/TopicModellingEnvi/lib/python3.9/site-packages/gensim/similarities/termsim.py:382: RuntimeWarning: invalid value encountered in multiply\n",
      "  normalized_corpus = np.multiply(corpus, 1.0 / corpus_norm)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1.0),\n",
       " (30, 0.40238836),\n",
       " (47, 0.3327572),\n",
       " (70, 0.31299573),\n",
       " (50, 0.27072102),\n",
       " (54, 0.24888347),\n",
       " (55, 0.24774396),\n",
       " (39, 0.23246586),\n",
       " (31, 0.22768083),\n",
       " (63, 0.21946782),\n",
       " (64, 0.21946782),\n",
       " (42, 0.20036793),\n",
       " (36, 0.19899526),\n",
       " (3, 0.19444132),\n",
       " (4, 0.19444132),\n",
       " (32, 0.19271162),\n",
       " (52, 0.18954234),\n",
       " (53, 0.16677529),\n",
       " (41, 0.1519109),\n",
       " (57, 0.1519109),\n",
       " (58, 0.1519109),\n",
       " (37, 0.13496515),\n",
       " (40, 0.13496515),\n",
       " (51, 0.13188994),\n",
       " (45, 0.13153924),\n",
       " (38, 0.12366057),\n",
       " (5, 0.11263094),\n",
       " (21, 0.11263094),\n",
       " (56, 0.08404977),\n",
       " (71, 0.06470154),\n",
       " (72, 0.06470154),\n",
       " (18, 0.063445084),\n",
       " (6, 0.02287545),\n",
       " (7, 0.02287545),\n",
       " (8, 0.02287545),\n",
       " (9, 0.02287545),\n",
       " (10, 0.02287545),\n",
       " (11, 0.02287545),\n",
       " (12, 0.02287545),\n",
       " (13, 0.02287545),\n",
       " (16, 0.02287545),\n",
       " (19, 0.02287545),\n",
       " (20, 0.02287545),\n",
       " (22, 0.02287545),\n",
       " (23, 0.02287545),\n",
       " (24, 0.02287545),\n",
       " (25, 0.02287545),\n",
       " (26, 0.02287545),\n",
       " (27, 0.02287545),\n",
       " (28, 0.02287545),\n",
       " (46, 0.02287545),\n",
       " (48, 0.02287545),\n",
       " (49, 0.02287545),\n",
       " (14, 0.020460425),\n",
       " (15, 0.020460425),\n",
       " (17, 0.020460425),\n",
       " (29, 0.020460425),\n",
       " (60, 0.017156588),\n",
       " (61, 0.017156588),\n",
       " (62, 0.017156588),\n",
       " (1, 0.0),\n",
       " (2, 0.0),\n",
       " (33, 0.0),\n",
       " (34, 0.0),\n",
       " (35, 0.0),\n",
       " (43, 0.0),\n",
       " (44, 0.0),\n",
       " (59, 0.0),\n",
       " (65, 0.0),\n",
       " (66, 0.0),\n",
       " (67, 0.0),\n",
       " (68, 0.0),\n",
       " (69, 0.0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "1. Training a Word2Vec embedding by the token list for getting the latent semantic.\n",
    "2. Using embedding to construct a term similarity matrix that will be used.\n",
    "3.  (1) Cosine similarity is a metric used to determine how similar the documents are irrespective of their size.\n",
    "    (2) Use the embedding in Soft Cosine similarity to get the relativities between documents.\n",
    "\"\"\"\n",
    "# train a word2vec model on token list,and get a similarity_matrix\n",
    "m = Word2Vec(retrievalHistoryReport['tokens'][0], min_count=1)      \n",
    "termsim_index = WordEmbeddingSimilarityIndex(m.wv)                  \n",
    "similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)\n",
    "\n",
    "# Giving the embedding and corpus to SoftCosineSimilarity method to get the similarities between documents.\n",
    "docsim_index = SoftCosineSimilarity(corpus=corpus,similarity_matrix=similarity_matrix,num_best=5)\n",
    "# Getting similarities of each doc\n",
    "sims = [docsim_index[dictionary.doc2bow(doc)] for doc in retrievalHistoryReport['tokens']]\n",
    "\n",
    "# Getting matrix similarity of each token in corpus, and seeing the relation between tokens in single doc.\n",
    "document_topic_matrix = similarities.MatrixSimilarity(corpus=corpus)\n",
    "document_topic_matrix_ix = document_topic_matrix.index\n",
    "sims = document_topic_matrix[corpus[0]]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
